{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,f1_score\n",
    "from random import randint\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,f1_score\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_data():\n",
    "    \n",
    "    # Reading the data into python \n",
    "    customer=pd.read_excel('LU_CUSTOMER.xlsx')\n",
    "    item=pd.read_excel('LU_ITEM.xlsx')\n",
    "    order=pd.read_excel('LU_ORDER.xlsx')\n",
    "    detail=pd.read_excel('ORDER_DETAIL.xlsx')\n",
    "    \n",
    "    #customer.head()\n",
    "    #item.head()\n",
    "    #detail.head()\n",
    "    #order.head()\n",
    "    \n",
    "    # Joining the Tables\n",
    "    order_details = pd.merge(order,detail, on=['CUSTOMER_ID','ORDER_ID'],how='outer')\n",
    "    order_details_cust = pd.merge(order_details,customer,on=['CUSTOMER_ID'],how='outer')\n",
    "    order_details_full = pd.merge(order_details_cust,item, on=['ITEM_ID','UNIT_PRICE','UNIT_COST'],how='outer')\n",
    "    df = order_details_full.drop(['ORDER_DATE','CUST_LAST_NAME','CUST_FIRST_NAME','CUST_BIRTHDATE','EMAIL','ADDRESS','BRACKET_DESC','CUST_CITY_NAME','ITEM_NAME','ITEM_LONG_DESC'], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Preproccess_data(df):\n",
    "    \n",
    "    # Missing value imputation with a negative value \n",
    "    df.fillna(-1,inplace=True)\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Train_model(df,clf):\n",
    "    \n",
    "    # Creating the Target and Independant variables \n",
    "    X = df.drop(['CUSTOMER_ID','ORDER_ID'],axis=1)\n",
    "    y = df['CUSTOMER_ID']\n",
    "    \n",
    "    # Creating the prediciton model\n",
    "    \n",
    "    \n",
    "    #knn_mod.fit(X,y)\n",
    "    y_pred = cross_val_predict(clf,X,y,cv=8,n_jobs=-1)\n",
    "\n",
    "    # Results\n",
    "    print('Accuracy Score: ' + str(accuracy_score(y,y_pred)) + '\\n')\n",
    "    #print('Confusion Matrix: \\n ' + str(confusion_matrix(y,y_pred)) + '\\n')\n",
    "    #print('F1 Score: ' + str(f1_score(y,y_pred, average='macro')))\n",
    "    \n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibMemoryError",
     "evalue": "JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f7e0ea8ba30, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/anirud...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname='/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f7e0ea8ba30, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/anirud...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 6, 11, 15, 47, 653203, tzinfo=tzutc()), u'msg_id': u'B4F4BB802729467A858F58A6B172F944', u'msg_type': u'execute_request', u'session': u'6D196E6C8ACB4743BCB74E5DE9655626', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'B4F4BB802729467A858F58A6B172F944', 'msg_type': u'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['6D196E6C8ACB4743BCB74E5DE9655626']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 6, 11, 15, 47, 653203, tzinfo=tzutc()), u'msg_id': u'B4F4BB802729467A858F58A6B172F944', u'msg_type': u'execute_request', u'session': u'6D196E6C8ACB4743BCB74E5DE9655626', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'B4F4BB802729467A858F58A6B172F944', 'msg_type': u'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['6D196E6C8ACB4743BCB74E5DE9655626'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 6, 11, 15, 47, 653203, tzinfo=tzutc()), u'msg_id': u'B4F4BB802729467A858F58A6B172F944', u'msg_type': u'execute_request', u'session': u'6D196E6C8ACB4743BCB74E5DE9655626', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'B4F4BB802729467A858F58A6B172F944', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    '\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.If object>], cell_name='<ipython-input-7-78330300e083>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7f7e0136d390, executi..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f7dbbef7eb0, file \"<ipython-input-7-78330300e083>\", line 1>\n        result = <ExecutionResult object at 7f7e0136d390, executi..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f7dbbef7eb0, file \"<ipython-input-7-78330300e083>\", line 1>, result=<ExecutionResult object at 7f7e0136d390, executi..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f7dbbef7eb0, file \"<ipython-input-7-78330300e083>\", line 1>\n        self.user_global_ns = {'In': ['', u'import pandas as pd\\nimport numpy as np\\nfrom ...\\nfrom sklearn.preprocessing import LabelEncoder', u\"def create_data():\\n    \\n    # Reading the da...,'ITEM_LONG_DESC'], axis=1)\\n    \\n    return df\", u'def Preproccess_data(df):\\n    \\n    # Missing...llna(-1,inplace=True)\\n    \\n    return df\\n    ', u\"def Train_model(df,clf):\\n    \\n    # Creating...red, average='macro')))\\n    \\n    return y_pred\", u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ', u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ', u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    '], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'OneHotEncoder': <class 'sklearn.preprocessing.data.OneHotEncoder'>, 'Out': {}, 'Preproccess_data': <function Preproccess_data>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'Train_model': <function Train_model>, ...}\n        self.user_ns = {'In': ['', u'import pandas as pd\\nimport numpy as np\\nfrom ...\\nfrom sklearn.preprocessing import LabelEncoder', u\"def create_data():\\n    \\n    # Reading the da...,'ITEM_LONG_DESC'], axis=1)\\n    \\n    return df\", u'def Preproccess_data(df):\\n    \\n    # Missing...llna(-1,inplace=True)\\n    \\n    return df\\n    ', u\"def Train_model(df,clf):\\n    \\n    # Creating...red, average='macro')))\\n    \\n    return y_pred\", u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ', u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ', u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    '], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'OneHotEncoder': <class 'sklearn.preprocessing.data.OneHotEncoder'>, 'Out': {}, 'Preproccess_data': <function Preproccess_data>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'Train_model': <function Train_model>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/media/anirudh/Data/Code/Bugscience/Assignments_Internship/Round1_Assignment 1 (of 2)_Research/Round1_Assignment 1 (of 2)_Research/Data_Round1_Assignment 1 (of 2)_Research/<ipython-input-7-78330300e083> in <module>()\n      6     #clf = KNeighborsClassifier()\n      7     #y_cols = ['CUSTOMER_ID','ORDER_ID']\n      8     \n      9     clf = MLPClassifier(hidden_layer_sizes=(10))\n     10     \n---> 11     y_pred = Train_model(df,clf)\n     12     \n     13 \n     14 \n     15 \n\n...........................................................................\n/media/anirudh/Data/Code/Bugscience/Assignments_Internship/Round1_Assignment 1 (of 2)_Research/Round1_Assignment 1 (of 2)_Research/Data_Round1_Assignment 1 (of 2)_Research/<ipython-input-4-dd8335555c8e> in Train_model(df=        ORDER_ID  CUSTOMER_ID  PYMT_TYPE  SHIPPE...      109       173  \n\n[407529 rows x 19 columns], clf=MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n       verbose=False, warm_start=False))\n      6     \n      7     # Creating the prediciton model\n      8     \n      9     \n     10     #knn_mod.fit(X,y)\n---> 11     y_pred = cross_val_predict(clf,X,y,cv=8,n_jobs=-1)\n     12 \n     13     # Results\n     14     print('Accuracy Score: ' + str(accuracy_score(y,y_pred)) + '\\n')\n     15     #print('Confusion Matrix: \\n ' + str(confusion_matrix(y,y_pred)) + '\\n')\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_val_predict(estimator=MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n       verbose=False, warm_start=False), X=        PYMT_TYPE  SHIPPER_ID  ITEM_ID  EMP_ID  ...      109       173  \n\n[407529 rows x 17 columns], y=0           26\n1          180\n2           76\n3  ...0\nName: CUSTOMER_ID, Length: 407529, dtype: int64, groups=None, cv=StratifiedKFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', method='predict')\n    396     # independent, and that it is pickle-able.\n    397     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n    398                         pre_dispatch=pre_dispatch)\n    399     prediction_blocks = parallel(delayed(_fit_and_predict)(\n    400         clone(estimator), X, y, train, test, verbose, fit_params, method)\n--> 401         for train, test in cv_iter)\n        cv_iter = [(array([  3014,   5820,   7769, ..., 407526, 407527, 407528]), array([     0,      1,      2, ..., 167798, 172409, 174202])), (array([     0,      1,      2, ..., 407526, 407527, 407528]), array([  3014,   5820,   7769, ..., 252905, 257772, 263851])), (array([     0,      1,      2, ..., 407526, 407527, 407528]), array([ 18956,  28113,  28346, ..., 297644, 309907, 338535])), (array([     0,      1,      2, ..., 407526, 407527, 407528]), array([ 38135,  38410,  38411, ..., 344410, 350617, 358378])), (array([     0,      1,      2, ..., 407526, 407527, 407528]), array([ 45917,  48406,  50075, ..., 377821, 379409, 381303])), (array([     0,      1,      2, ..., 407526, 407527, 407528]), array([ 61747,  65495,  67399, ..., 390088, 391256, 395787])), (array([     0,      1,      2, ..., 407526, 407527, 407528]), array([ 76295,  77231,  77572, ..., 403570, 403674, 404906])), (array([     0,      1,      2, ..., 403570, 403674, 404906]), array([ 91016,  93775,  96075, ..., 407526, 407527, 407528]))]\n    402 \n    403     # Concatenate the predictions\n    404     predictions = [pred_block_i for pred_block_i, _ in prediction_blocks]\n    405     test_indices = np.concatenate([indices_i\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Wed Dec  6 16:47:02 2017\nPID: 18107                 Python 2.7.13: /home/anirudh/anaconda/bin/python\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_predict>\n        args = (MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n       verbose=False, warm_start=False),         PYMT_TYPE  SHIPPER_ID  ITEM_ID  EMP_ID  ...      109       173  \n\n[407529 rows x 17 columns], 0           26\n1          180\n2           76\n3  ...0\nName: CUSTOMER_ID, Length: 407529, dtype: int64, memmap([  3014,   5820,   7769, ..., 407526, 407527, 407528]), array([     0,      1,      2, ..., 167798, 172409, 174202]), 0, None, 'predict')\n        kwargs = {}\n        self.items = [(<function _fit_and_predict>, (MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n       verbose=False, warm_start=False),         PYMT_TYPE  SHIPPER_ID  ITEM_ID  EMP_ID  ...      109       173  \n\n[407529 rows x 17 columns], 0           26\n1          180\n2           76\n3  ...0\nName: CUSTOMER_ID, Length: 407529, dtype: int64, memmap([  3014,   5820,   7769, ..., 407526, 407527, 407528]), array([     0,      1,      2, ..., 167798, 172409, 174202]), 0, None, 'predict'), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_predict(estimator=MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n       verbose=False, warm_start=False), X=        PYMT_TYPE  SHIPPER_ID  ITEM_ID  EMP_ID  ...      109       173  \n\n[407529 rows x 17 columns], y=0           26\n1          180\n2           76\n3  ...0\nName: CUSTOMER_ID, Length: 407529, dtype: int64, train=memmap([  3014,   5820,   7769, ..., 407526, 407527, 407528]), test=array([     0,      1,      2, ..., 167798, 172409, 174202]), verbose=0, fit_params={}, method='predict')\n    469     X_test, _ = _safe_split(estimator, X, y, test, train)\n    470 \n    471     if y_train is None:\n    472         estimator.fit(X_train, **fit_params)\n    473     else:\n--> 474         estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method MLPClassifier.fit of MLPClassifier...ion=0.1,\n       verbose=False, warm_start=False)>\n        X_train =         PYMT_TYPE  SHIPPER_ID  ITEM_ID  EMP_ID  ...      109       173  \n\n[352209 rows x 17 columns]\n        y_train = 3014      1105\n5820      5405\n7769      1915\n110...0\nName: CUSTOMER_ID, Length: 352209, dtype: int64\n        fit_params = {}\n    475     func = getattr(estimator, method)\n    476     predictions = func(X_test)\n    477     return predictions, test\n    478 \n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py in fit(self=MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n       verbose=False, warm_start=False), X=        PYMT_TYPE  SHIPPER_ID  ITEM_ID  EMP_ID  ...      109       173  \n\n[352209 rows x 17 columns], y=3014      1105\n5820      5405\n7769      1915\n110...0\nName: CUSTOMER_ID, Length: 352209, dtype: int64)\n    613 \n    614         Returns\n    615         -------\n    616         self : returns a trained MLP model.\n    617         \"\"\"\n--> 618         return self._fit(X, y, incremental=False)\n        self._fit = <bound method MLPClassifier._fit of MLPClassifie...ion=0.1,\n       verbose=False, warm_start=False)>\n        X =         PYMT_TYPE  SHIPPER_ID  ITEM_ID  EMP_ID  ...      109       173  \n\n[352209 rows x 17 columns]\n        y = 3014      1105\n5820      5405\n7769      1915\n110...0\nName: CUSTOMER_ID, Length: 352209, dtype: int64\n    619 \n    620     @property\n    621     def partial_fit(self):\n    622         \"\"\"Fit the model to data matrix X and target y.\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py in _fit(self=MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n       verbose=False, warm_start=False), X=array([[  3,   1, 216, ...,  33, 306, 349],\n    ...73],\n       [  2,   1,  60, ...,  14, 109, 173]]), y=array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]]), incremental=False)\n    372                            layer_units[1:]]\n    373 \n    374         # Run the Stochastic optimization solver\n    375         if self.solver in _STOCHASTIC_SOLVERS:\n    376             self._fit_stochastic(X, y, activations, deltas, coef_grads,\n--> 377                                  intercept_grads, layer_units, incremental)\n        intercept_grads = [array([  2.96439388e-322,   3.01380044e-322,   3...22,   3.35964639e-322,\n         3.40905296e-322]), array([  1.27721843e-315,   1.14046216e-315,   1...6833e-320,   4.94016239e-320,   4.94065646e-320])]\n        layer_units = [17, 10, 10000]\n        incremental = False\n    378 \n    379         # Run the LBFGS solver\n    380         elif self.solver == 'lbfgs':\n    381             self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py in _fit_stochastic(self=MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n       verbose=False, warm_start=False), X=array([[  3,   1, 216, ...,  33, 306, 349],\n    ...73],\n       [  2,   1,  60, ...,  14, 109, 173]]), y=array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]]), activations=[array([[  3,   1, 216, ...,  33, 306, 349],\n    ...73],\n       [  2,   1,  60, ...,  14, 109, 173]]), array([[  4.80920575e-316,   1.28150803e-315,   ...258e-323,   1.97626258e-323,   1.97626258e-323]]), array([[  9.48956629e-316,   2.41106051e-315,   ...293e-310,   6.92571293e-310,   6.92571293e-310]])], deltas=[array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]]), array([[  4.80920575e-316,   1.49689235e-315,   ...070e-315,   2.22329541e-322,   2.27270197e-322]]), array([[  1.62055152e-315,   6.92578130e-310,   ...646e-324,   4.94065646e-324,   4.94065646e-324]])], coef_grads=[array([[  6.92578130e-310,   4.82209335e-316,   ...,   9.38312874e-317,\n          6.92578130e-310]]), array([[  1.41272000e-315,   3.89915185e-316,   ...000e+000,   0.00000000e+000,   1.35334632e-315]])], intercept_grads=[array([  2.96439388e-322,   3.01380044e-322,   3...22,   3.35964639e-322,\n         3.40905296e-322]), array([  1.27721843e-315,   1.14046216e-315,   1...6833e-320,   4.94016239e-320,   4.94065646e-320])], layer_units=[17, 10, 10000], incremental=False)\n    504         else:\n    505             batch_size = np.clip(self.batch_size, 1, n_samples)\n    506 \n    507         try:\n    508             for it in range(self.max_iter):\n--> 509                 X, y = shuffle(X, y, random_state=self._random_state)\n        X = array([[  3,   1, 216, ...,  33, 306, 349],\n    ...73],\n       [  2,   1,  60, ...,  14, 109, 173]])\n        y = array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])\n        self._random_state = <mtrand.RandomState object>\n    510                 accumulated_loss = 0.0\n    511                 for batch_slice in gen_batches(n_samples, batch_size):\n    512                     activations[0] = X[batch_slice]\n    513                     batch_loss, coef_grads, intercept_grads = self._backprop(\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/utils/__init__.py in shuffle(*arrays=(array([[  3,   1, 216, ...,  33, 306, 349],\n    ...73],\n       [  2,   1,  60, ...,  14, 109, 173]]), array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])), **options={'random_state': <mtrand.RandomState object>, 'replace': False})\n    280     See also\n    281     --------\n    282     :func:`sklearn.utils.resample`\n    283     \"\"\"\n    284     options['replace'] = False\n--> 285     return resample(*arrays, **options)\n        arrays = (array([[  3,   1, 216, ...,  33, 306, 349],\n    ...73],\n       [  2,   1,  60, ...,  14, 109, 173]]), array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]]))\n        options = {'random_state': <mtrand.RandomState object>, 'replace': False}\n    286 \n    287 \n    288 def safe_sqr(X, copy=True):\n    289     \"\"\"Element wise squaring of array-likes and sparse matrices.\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/utils/__init__.py in resample(*arrays=[array([[  3,   1, 216, ...,  33, 306, 349],\n    ...73],\n       [  2,   1,  60, ...,  14, 109, 173]]), array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])], **options={})\n    210         random_state.shuffle(indices)\n    211         indices = indices[:max_n_samples]\n    212 \n    213     # convert sparse matrices to CSR for row-based indexing\n    214     arrays = [a.tocsr() if issparse(a) else a for a in arrays]\n--> 215     resampled_arrays = [safe_indexing(a, indices) for a in arrays]\n        resampled_arrays = undefined\n        a = array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])\n        indices = array([267878, 304878, 338922, ...,  66100,   8290,  26745])\n        arrays = [array([[  3,   1, 216, ...,  33, 306, 349],\n    ...73],\n       [  2,   1,  60, ...,  14, 109, 173]]), array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])]\n    216     if len(resampled_arrays) == 1:\n    217         # syntactic sugar for the unit argument case\n    218         return resampled_arrays[0]\n    219     else:\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/utils/__init__.py in safe_indexing(X=array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]]), indices=array([267878, 304878, 338922, ...,  66100,   8290,  26745]))\n    105             return X.copy().iloc[indices]\n    106     elif hasattr(X, \"shape\"):\n    107         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    108                                    indices.dtype.kind == 'i'):\n    109             # This is often substantially faster than X[indices]\n--> 110             return X.take(indices, axis=0)\n        X.take = <built-in method take of numpy.ndarray object>\n        indices = array([267878, 304878, 338922, ...,  66100,   8290,  26745])\n    111         else:\n    112             return X[indices]\n    113     else:\n    114         return [X[idx] for idx in indices]\n\nMemoryError: \n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJoblibMemoryError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-78330300e083>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-dd8335555c8e>\u001b[0m in \u001b[0;36mTrain_model\u001b[0;34m(df, clf)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#knn_mod.fit(X,y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36mcross_val_predict\u001b[0;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[1;32m    399\u001b[0m     prediction_blocks = parallel(delayed(_fit_and_predict)(\n\u001b[1;32m    400\u001b[0m         clone(estimator), X, y, train, test, verbose, fit_params, method)\n\u001b[0;32m--> 401\u001b[0;31m         for train, test in cv_iter)\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;31m# Concatenate the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibMemoryError\u001b[0m: JoblibMemoryError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f7e0ea8ba30, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/anirud...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname='/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f7e0ea8ba30, file \"/...2.7/site-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/home/anirud...python2.7/site-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 6, 11, 15, 47, 653203, tzinfo=tzutc()), u'msg_id': u'B4F4BB802729467A858F58A6B172F944', u'msg_type': u'execute_request', u'session': u'6D196E6C8ACB4743BCB74E5DE9655626', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'B4F4BB802729467A858F58A6B172F944', 'msg_type': u'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['6D196E6C8ACB4743BCB74E5DE9655626']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 6, 11, 15, 47, 653203, tzinfo=tzutc()), u'msg_id': u'B4F4BB802729467A858F58A6B172F944', u'msg_type': u'execute_request', u'session': u'6D196E6C8ACB4743BCB74E5DE9655626', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'B4F4BB802729467A858F58A6B172F944', 'msg_type': u'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['6D196E6C8ACB4743BCB74E5DE9655626'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2017, 12, 6, 11, 15, 47, 653203, tzinfo=tzutc()), u'msg_id': u'B4F4BB802729467A858F58A6B172F944', u'msg_type': u'execute_request', u'session': u'6D196E6C8ACB4743BCB74E5DE9655626', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'B4F4BB802729467A858F58A6B172F944', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    '\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.If object>], cell_name='<ipython-input-7-78330300e083>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7f7e0136d390, executi..._before_exec=None error_in_exec=None result=None>)\n   2816 \n   2817         try:\n   2818             for i, node in enumerate(to_run_exec):\n   2819                 mod = ast.Module([node])\n   2820                 code = compiler(mod, cell_name, \"exec\")\n-> 2821                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f7dbbef7eb0, file \"<ipython-input-7-78330300e083>\", line 1>\n        result = <ExecutionResult object at 7f7e0136d390, executi..._before_exec=None error_in_exec=None result=None>\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f7dbbef7eb0, file \"<ipython-input-7-78330300e083>\", line 1>, result=<ExecutionResult object at 7f7e0136d390, executi..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f7dbbef7eb0, file \"<ipython-input-7-78330300e083>\", line 1>\n        self.user_global_ns = {'In': ['', u'import pandas as pd\\nimport numpy as np\\nfrom ...\\nfrom sklearn.preprocessing import LabelEncoder', u\"def create_data():\\n    \\n    # Reading the da...,'ITEM_LONG_DESC'], axis=1)\\n    \\n    return df\", u'def Preproccess_data(df):\\n    \\n    # Missing...llna(-1,inplace=True)\\n    \\n    return df\\n    ', u\"def Train_model(df,clf):\\n    \\n    # Creating...red, average='macro')))\\n    \\n    return y_pred\", u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ', u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ', u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    '], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'OneHotEncoder': <class 'sklearn.preprocessing.data.OneHotEncoder'>, 'Out': {}, 'Preproccess_data': <function Preproccess_data>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'Train_model': <function Train_model>, ...}\n        self.user_ns = {'In': ['', u'import pandas as pd\\nimport numpy as np\\nfrom ...\\nfrom sklearn.preprocessing import LabelEncoder', u\"def create_data():\\n    \\n    # Reading the da...,'ITEM_LONG_DESC'], axis=1)\\n    \\n    return df\", u'def Preproccess_data(df):\\n    \\n    # Missing...llna(-1,inplace=True)\\n    \\n    return df\\n    ', u\"def Train_model(df,clf):\\n    \\n    # Creating...red, average='macro')))\\n    \\n    return y_pred\", u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ', u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    ', u'if __name__ == \"__main__\":\\n    \\n    df = cre...))\\n    \\n    y_pred = Train_model(df,clf)\\n    '], 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LabelEncoder': <class 'sklearn.preprocessing.label.LabelEncoder'>, 'MLPClassifier': <class 'sklearn.neural_network.multilayer_perceptron.MLPClassifier'>, 'OneHotEncoder': <class 'sklearn.preprocessing.data.OneHotEncoder'>, 'Out': {}, 'Preproccess_data': <function Preproccess_data>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, 'StandardScaler': <class 'sklearn.preprocessing.data.StandardScaler'>, 'Train_model': <function Train_model>, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/media/anirudh/Data/Code/Bugscience/Assignments_Internship/Round1_Assignment 1 (of 2)_Research/Round1_Assignment 1 (of 2)_Research/Data_Round1_Assignment 1 (of 2)_Research/<ipython-input-7-78330300e083> in <module>()\n      6     #clf = KNeighborsClassifier()\n      7     #y_cols = ['CUSTOMER_ID','ORDER_ID']\n      8     \n      9     clf = MLPClassifier(hidden_layer_sizes=(10))\n     10     \n---> 11     y_pred = Train_model(df,clf)\n     12     \n     13 \n     14 \n     15 \n\n...........................................................................\n/media/anirudh/Data/Code/Bugscience/Assignments_Internship/Round1_Assignment 1 (of 2)_Research/Round1_Assignment 1 (of 2)_Research/Data_Round1_Assignment 1 (of 2)_Research/<ipython-input-4-dd8335555c8e> in Train_model(df=        ORDER_ID  CUSTOMER_ID  PYMT_TYPE  SHIPPE...      109       173  \n\n[407529 rows x 19 columns], clf=MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n       verbose=False, warm_start=False))\n      6     \n      7     # Creating the prediciton model\n      8     \n      9     \n     10     #knn_mod.fit(X,y)\n---> 11     y_pred = cross_val_predict(clf,X,y,cv=8,n_jobs=-1)\n     12 \n     13     # Results\n     14     print('Accuracy Score: ' + str(accuracy_score(y,y_pred)) + '\\n')\n     15     #print('Confusion Matrix: \\n ' + str(confusion_matrix(y,y_pred)) + '\\n')\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in cross_val_predict(estimator=MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n       verbose=False, warm_start=False), X=        PYMT_TYPE  SHIPPER_ID  ITEM_ID  EMP_ID  ...      109       173  \n\n[407529 rows x 17 columns], y=0           26\n1          180\n2           76\n3  ...0\nName: CUSTOMER_ID, Length: 407529, dtype: int64, groups=None, cv=StratifiedKFold(n_splits=8, random_state=None, shuffle=False), n_jobs=-1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', method='predict')\n    396     # independent, and that it is pickle-able.\n    397     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n    398                         pre_dispatch=pre_dispatch)\n    399     prediction_blocks = parallel(delayed(_fit_and_predict)(\n    400         clone(estimator), X, y, train, test, verbose, fit_params, method)\n--> 401         for train, test in cv_iter)\n        cv_iter = [(array([  3014,   5820,   7769, ..., 407526, 407527, 407528]), array([     0,      1,      2, ..., 167798, 172409, 174202])), (array([     0,      1,      2, ..., 407526, 407527, 407528]), array([  3014,   5820,   7769, ..., 252905, 257772, 263851])), (array([     0,      1,      2, ..., 407526, 407527, 407528]), array([ 18956,  28113,  28346, ..., 297644, 309907, 338535])), (array([     0,      1,      2, ..., 407526, 407527, 407528]), array([ 38135,  38410,  38411, ..., 344410, 350617, 358378])), (array([     0,      1,      2, ..., 407526, 407527, 407528]), array([ 45917,  48406,  50075, ..., 377821, 379409, 381303])), (array([     0,      1,      2, ..., 407526, 407527, 407528]), array([ 61747,  65495,  67399, ..., 390088, 391256, 395787])), (array([     0,      1,      2, ..., 407526, 407527, 407528]), array([ 76295,  77231,  77572, ..., 403570, 403674, 404906])), (array([     0,      1,      2, ..., 403570, 403674, 404906]), array([ 91016,  93775,  96075, ..., 407526, 407527, 407528]))]\n    402 \n    403     # Concatenate the predictions\n    404     predictions = [pred_block_i for pred_block_i, _ in prediction_blocks]\n    405     test_indices = np.concatenate([indices_i\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object <genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nMemoryError                                        Wed Dec  6 16:47:02 2017\nPID: 18107                 Python 2.7.13: /home/anirudh/anaconda/bin/python\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_predict>\n        args = (MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n       verbose=False, warm_start=False),         PYMT_TYPE  SHIPPER_ID  ITEM_ID  EMP_ID  ...      109       173  \n\n[407529 rows x 17 columns], 0           26\n1          180\n2           76\n3  ...0\nName: CUSTOMER_ID, Length: 407529, dtype: int64, memmap([  3014,   5820,   7769, ..., 407526, 407527, 407528]), array([     0,      1,      2, ..., 167798, 172409, 174202]), 0, None, 'predict')\n        kwargs = {}\n        self.items = [(<function _fit_and_predict>, (MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n       verbose=False, warm_start=False),         PYMT_TYPE  SHIPPER_ID  ITEM_ID  EMP_ID  ...      109       173  \n\n[407529 rows x 17 columns], 0           26\n1          180\n2           76\n3  ...0\nName: CUSTOMER_ID, Length: 407529, dtype: int64, memmap([  3014,   5820,   7769, ..., 407526, 407527, 407528]), array([     0,      1,      2, ..., 167798, 172409, 174202]), 0, None, 'predict'), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/model_selection/_validation.py in _fit_and_predict(estimator=MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n       verbose=False, warm_start=False), X=        PYMT_TYPE  SHIPPER_ID  ITEM_ID  EMP_ID  ...      109       173  \n\n[407529 rows x 17 columns], y=0           26\n1          180\n2           76\n3  ...0\nName: CUSTOMER_ID, Length: 407529, dtype: int64, train=memmap([  3014,   5820,   7769, ..., 407526, 407527, 407528]), test=array([     0,      1,      2, ..., 167798, 172409, 174202]), verbose=0, fit_params={}, method='predict')\n    469     X_test, _ = _safe_split(estimator, X, y, test, train)\n    470 \n    471     if y_train is None:\n    472         estimator.fit(X_train, **fit_params)\n    473     else:\n--> 474         estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method MLPClassifier.fit of MLPClassifier...ion=0.1,\n       verbose=False, warm_start=False)>\n        X_train =         PYMT_TYPE  SHIPPER_ID  ITEM_ID  EMP_ID  ...      109       173  \n\n[352209 rows x 17 columns]\n        y_train = 3014      1105\n5820      5405\n7769      1915\n110...0\nName: CUSTOMER_ID, Length: 352209, dtype: int64\n        fit_params = {}\n    475     func = getattr(estimator, method)\n    476     predictions = func(X_test)\n    477     return predictions, test\n    478 \n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py in fit(self=MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n       verbose=False, warm_start=False), X=        PYMT_TYPE  SHIPPER_ID  ITEM_ID  EMP_ID  ...      109       173  \n\n[352209 rows x 17 columns], y=3014      1105\n5820      5405\n7769      1915\n110...0\nName: CUSTOMER_ID, Length: 352209, dtype: int64)\n    613 \n    614         Returns\n    615         -------\n    616         self : returns a trained MLP model.\n    617         \"\"\"\n--> 618         return self._fit(X, y, incremental=False)\n        self._fit = <bound method MLPClassifier._fit of MLPClassifie...ion=0.1,\n       verbose=False, warm_start=False)>\n        X =         PYMT_TYPE  SHIPPER_ID  ITEM_ID  EMP_ID  ...      109       173  \n\n[352209 rows x 17 columns]\n        y = 3014      1105\n5820      5405\n7769      1915\n110...0\nName: CUSTOMER_ID, Length: 352209, dtype: int64\n    619 \n    620     @property\n    621     def partial_fit(self):\n    622         \"\"\"Fit the model to data matrix X and target y.\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py in _fit(self=MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n       verbose=False, warm_start=False), X=array([[  3,   1, 216, ...,  33, 306, 349],\n    ...73],\n       [  2,   1,  60, ...,  14, 109, 173]]), y=array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]]), incremental=False)\n    372                            layer_units[1:]]\n    373 \n    374         # Run the Stochastic optimization solver\n    375         if self.solver in _STOCHASTIC_SOLVERS:\n    376             self._fit_stochastic(X, y, activations, deltas, coef_grads,\n--> 377                                  intercept_grads, layer_units, incremental)\n        intercept_grads = [array([  2.96439388e-322,   3.01380044e-322,   3...22,   3.35964639e-322,\n         3.40905296e-322]), array([  1.27721843e-315,   1.14046216e-315,   1...6833e-320,   4.94016239e-320,   4.94065646e-320])]\n        layer_units = [17, 10, 10000]\n        incremental = False\n    378 \n    379         # Run the LBFGS solver\n    380         elif self.solver == 'lbfgs':\n    381             self._fit_lbfgs(X, y, activations, deltas, coef_grads,\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/neural_network/multilayer_perceptron.py in _fit_stochastic(self=MLPClassifier(activation='relu', alpha=0.0001, b...tion=0.1,\n       verbose=False, warm_start=False), X=array([[  3,   1, 216, ...,  33, 306, 349],\n    ...73],\n       [  2,   1,  60, ...,  14, 109, 173]]), y=array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]]), activations=[array([[  3,   1, 216, ...,  33, 306, 349],\n    ...73],\n       [  2,   1,  60, ...,  14, 109, 173]]), array([[  4.80920575e-316,   1.28150803e-315,   ...258e-323,   1.97626258e-323,   1.97626258e-323]]), array([[  9.48956629e-316,   2.41106051e-315,   ...293e-310,   6.92571293e-310,   6.92571293e-310]])], deltas=[array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]]), array([[  4.80920575e-316,   1.49689235e-315,   ...070e-315,   2.22329541e-322,   2.27270197e-322]]), array([[  1.62055152e-315,   6.92578130e-310,   ...646e-324,   4.94065646e-324,   4.94065646e-324]])], coef_grads=[array([[  6.92578130e-310,   4.82209335e-316,   ...,   9.38312874e-317,\n          6.92578130e-310]]), array([[  1.41272000e-315,   3.89915185e-316,   ...000e+000,   0.00000000e+000,   1.35334632e-315]])], intercept_grads=[array([  2.96439388e-322,   3.01380044e-322,   3...22,   3.35964639e-322,\n         3.40905296e-322]), array([  1.27721843e-315,   1.14046216e-315,   1...6833e-320,   4.94016239e-320,   4.94065646e-320])], layer_units=[17, 10, 10000], incremental=False)\n    504         else:\n    505             batch_size = np.clip(self.batch_size, 1, n_samples)\n    506 \n    507         try:\n    508             for it in range(self.max_iter):\n--> 509                 X, y = shuffle(X, y, random_state=self._random_state)\n        X = array([[  3,   1, 216, ...,  33, 306, 349],\n    ...73],\n       [  2,   1,  60, ...,  14, 109, 173]])\n        y = array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])\n        self._random_state = <mtrand.RandomState object>\n    510                 accumulated_loss = 0.0\n    511                 for batch_slice in gen_batches(n_samples, batch_size):\n    512                     activations[0] = X[batch_slice]\n    513                     batch_loss, coef_grads, intercept_grads = self._backprop(\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/utils/__init__.py in shuffle(*arrays=(array([[  3,   1, 216, ...,  33, 306, 349],\n    ...73],\n       [  2,   1,  60, ...,  14, 109, 173]]), array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])), **options={'random_state': <mtrand.RandomState object>, 'replace': False})\n    280     See also\n    281     --------\n    282     :func:`sklearn.utils.resample`\n    283     \"\"\"\n    284     options['replace'] = False\n--> 285     return resample(*arrays, **options)\n        arrays = (array([[  3,   1, 216, ...,  33, 306, 349],\n    ...73],\n       [  2,   1,  60, ...,  14, 109, 173]]), array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]]))\n        options = {'random_state': <mtrand.RandomState object>, 'replace': False}\n    286 \n    287 \n    288 def safe_sqr(X, copy=True):\n    289     \"\"\"Element wise squaring of array-likes and sparse matrices.\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/utils/__init__.py in resample(*arrays=[array([[  3,   1, 216, ...,  33, 306, 349],\n    ...73],\n       [  2,   1,  60, ...,  14, 109, 173]]), array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])], **options={})\n    210         random_state.shuffle(indices)\n    211         indices = indices[:max_n_samples]\n    212 \n    213     # convert sparse matrices to CSR for row-based indexing\n    214     arrays = [a.tocsr() if issparse(a) else a for a in arrays]\n--> 215     resampled_arrays = [safe_indexing(a, indices) for a in arrays]\n        resampled_arrays = undefined\n        a = array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])\n        indices = array([267878, 304878, 338922, ...,  66100,   8290,  26745])\n        arrays = [array([[  3,   1, 216, ...,  33, 306, 349],\n    ...73],\n       [  2,   1,  60, ...,  14, 109, 173]]), array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])]\n    216     if len(resampled_arrays) == 1:\n    217         # syntactic sugar for the unit argument case\n    218         return resampled_arrays[0]\n    219     else:\n\n...........................................................................\n/home/anirudh/anaconda/lib/python2.7/site-packages/sklearn/utils/__init__.py in safe_indexing(X=array([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0,..., ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]]), indices=array([267878, 304878, 338922, ...,  66100,   8290,  26745]))\n    105             return X.copy().iloc[indices]\n    106     elif hasattr(X, \"shape\"):\n    107         if hasattr(X, 'take') and (hasattr(indices, 'dtype') and\n    108                                    indices.dtype.kind == 'i'):\n    109             # This is often substantially faster than X[indices]\n--> 110             return X.take(indices, axis=0)\n        X.take = <built-in method take of numpy.ndarray object>\n        indices = array([267878, 304878, 338922, ...,  66100,   8290,  26745])\n    111         else:\n    112             return X[indices]\n    113     else:\n    114         return [X[idx] for idx in indices]\n\nMemoryError: \n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    df = create_data()\n",
    "    df = Preproccess_data(df)\n",
    "    \n",
    "    #clf = KNeighborsClassifier()\n",
    "    #y_cols = ['CUSTOMER_ID','ORDER_ID']\n",
    "    \n",
    "    clf = MLPClassifier(hidden_layer_sizes=(10))\n",
    "    \n",
    "    y_pred = Train_model(df,clf)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
